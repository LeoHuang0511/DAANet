{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/02-02_13-59_vgg_NoKPI_DWD_HT21_5e-05_5e-05/ep_10_iter_25000_mae_6.466_mse_7.215_seq_MAE_24.874_seq_MSE_24.874_WRAE_37.688_MIAE_3.396_MOAE_5.105.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/02-02_13-59_vgg_NoKPI_DWD_HT21_5e-05_5e-05/ep_10_iter_26000_mae_2.642_mse_3.087_seq_MAE_49.011_seq_MSE_49.011_WRAE_74.260_MIAE_5.415_MOAE_6.810.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/02-02_13-59_vgg_NoKPI_DWD_HT21_5e-05_5e-05/ep_1_iter_1000_mae_12.012_mse_13.032_seq_MAE_192.413_seq_MSE_192.413_WRAE_291.535_MIAE_19.843_MOAE_20.777.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/02-02_13-59_vgg_NoKPI_DWD_HT21_5e-05_5e-05/ep_1_iter_2000_mae_5.361_mse_5.964_seq_MAE_148.072_seq_MSE_148.072_WRAE_224.352_MIAE_15.892_MOAE_17.071.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/02-02_13-59_vgg_NoKPI_DWD_HT21_5e-05_5e-05/ep_2_iter_3000_mae_4.456_mse_5.104_seq_MAE_140.499_seq_MSE_140.499_WRAE_212.877_MIAE_15.205_MOAE_16.430.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/02-02_13-59_vgg_NoKPI_DWD_HT21_5e-05_5e-05/ep_2_iter_4000_mae_3.991_mse_4.478_seq_MAE_133.713_seq_MSE_133.713_WRAE_202.595_MIAE_14.483_MOAE_15.728.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/02-02_13-59_vgg_NoKPI_DWD_HT21_5e-05_5e-05/ep_3_iter_6000_mae_5.702_mse_6.304_seq_MAE_126.662_seq_MSE_126.662_WRAE_191.912_MIAE_13.318_MOAE_14.328.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/02-02_13-59_vgg_NoKPI_DWD_HT21_5e-05_5e-05/ep_3_iter_7000_mae_3.488_mse_4.218_seq_MAE_99.891_seq_MSE_99.891_WRAE_151.351_MIAE_10.918_MOAE_11.711.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/02-02_13-59_vgg_NoKPI_DWD_HT21_5e-05_5e-05/ep_4_iter_10000_mae_4.345_mse_5.000_seq_MAE_80.523_seq_MSE_80.523_WRAE_122.005_MIAE_8.480_MOAE_10.161.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/02-02_13-59_vgg_NoKPI_DWD_HT21_5e-05_5e-05/ep_5_iter_13000_mae_3.546_mse_3.946_seq_MAE_92.949_seq_MSE_92.949_WRAE_140.831_MIAE_9.752_MOAE_10.854.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/02-02_13-59_vgg_NoKPI_DWD_HT21_5e-05_5e-05/ep_6_iter_14000_mae_3.270_mse_4.499_seq_MAE_57.572_seq_MSE_57.572_WRAE_87.231_MIAE_6.524_MOAE_7.541.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/02-02_13-59_vgg_NoKPI_DWD_HT21_5e-05_5e-05/ep_6_iter_15000_mae_3.515_mse_3.804_seq_MAE_61.602_seq_MSE_61.602_WRAE_93.336_MIAE_6.447_MOAE_7.680.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/02-02_13-59_vgg_NoKPI_DWD_HT21_5e-05_5e-05/ep_7_iter_16000_mae_4.644_mse_5.539_seq_MAE_46.411_seq_MSE_46.411_WRAE_70.319_MIAE_4.759_MOAE_6.361.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/02-02_13-59_vgg_NoKPI_DWD_HT21_5e-05_5e-05/ep_7_iter_17000_mae_2.666_mse_3.321_seq_MAE_49.788_seq_MSE_49.788_WRAE_75.437_MIAE_5.440_MOAE_7.220.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/02-02_13-59_vgg_NoKPI_DWD_HT21_5e-05_5e-05/ep_8_iter_19000_mae_2.544_mse_3.101_seq_MAE_58.180_seq_MSE_58.180_WRAE_88.151_MIAE_6.304_MOAE_8.011.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/02-02_13-59_vgg_NoKPI_DWD_HT21_5e-05_5e-05/ep_8_iter_20000_mae_3.852_mse_4.389_seq_MAE_50.346_seq_MSE_50.346_WRAE_76.283_MIAE_5.058_MOAE_6.352.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/02-02_13-59_vgg_NoKPI_DWD_HT21_5e-05_5e-05/ep_8_iter_21000_mae_3.114_mse_3.560_seq_MAE_45.053_seq_MSE_45.053_WRAE_68.263_MIAE_4.796_MOAE_6.982.pth --GPU_ID 0\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "dataset = \"SENSE\"\n",
    "exp = \"02-01_16-13_vgg_NoKPI_DWD_SENSE_5e-05_0.0001\"\n",
    "device = \"TWCC\"\n",
    "gpu = 0\n",
    "\n",
    "if device == \"TWCC\":\n",
    "    root = \"/home/leohuang0511\"\n",
    "else:\n",
    "    root = \"/nfs/home/leo0511/Research\"\n",
    "files = sorted(glob.glob(f\"{root}/SSSP/exp/{dataset}/FT/{exp}/ep*\"))\n",
    "for file in files:\n",
    "    print(f\"python test_{dataset}.py --MODEL_PATH {file} --GPU_ID {gpu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "from importlib import import_module\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--EXP_NAME', type=str, default='')\n",
    "\n",
    "parser.add_argument('--RESUME_PATH',type=str, default='')\n",
    "parser.add_argument('--PRETRAIN_PATH',type=str, default='')\n",
    "parser.add_argument('--FROZEN', default=False, action='store_true', help=\"frozen pretrained frontend weights\")\n",
    "\n",
    "\n",
    "parser.add_argument('--GPU_ID', type=str, default='0')\n",
    "parser.add_argument('--SEED', type=int, default=3035)\n",
    "parser.add_argument('--DATASET', type=str, default='HT21')\n",
    "parser.add_argument('--TASK', type=str, default='FT')\n",
    "parser.add_argument('--PRINT_FREQ', type=int, default=20)\n",
    "parser.add_argument('--SAVE_VIS_FREQ', type=int, default=500)\n",
    "parser.add_argument('--BACKBONE', type=str, default='vgg')\n",
    "\n",
    "\n",
    "parser.add_argument('--LR_MIN', type=float, default=1e-6)\n",
    "parser.add_argument('--LR_BASE', type=float, default=5e-5, help='density branch')\n",
    "parser.add_argument('--LR_THRE', type=float, default=1e-4, help='mask branch')\n",
    "parser.add_argument('--LR_DECAY', type=float, default=0.95)\n",
    "parser.add_argument('--WEIGHT_DECAY', type=float, default=1e-5)\n",
    "parser.add_argument('--WARMUP_EPOCH', type=int, default=3, help='number of epochs for warm up step in cosine annealing lr scheduler')\n",
    "parser.add_argument('--MAX_EPOCH', type=int, default=20)\n",
    "parser.add_argument('--WORKER', type=int, default=4)\n",
    "\n",
    "\n",
    "parser.add_argument('--CON_WEIGHT', type=float, default=0.5)\n",
    "parser.add_argument('--SCALE_WEIGHT', type=float, nargs='+', default=[2,0.1,0.01])\n",
    "parser.add_argument('--CNT_WEIGHT', type=float, default=10)\n",
    "parser.add_argument('--MASK_WEIGHT', type=float, default=1)\n",
    "parser.add_argument('--IO_WEIGHT', type=float, default=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#_test or val\n",
    "parser.add_argument('--VAL_FREQ', type=int, default=1000)\n",
    "parser.add_argument('--VAL_START', type=int, default=1)\n",
    "parser.add_argument('--VAL_BATCH_SIZE', type=int, default=1)\n",
    "\n",
    "\n",
    "\n",
    "#_train\n",
    "parser.add_argument('--TRAIN_SIZE', type=int, nargs='+', default=[768,1024])\n",
    "parser.add_argument('--TRAIN_FRAME_INTERVALS', type=int, nargs='+', default=[40, 85])\n",
    "parser.add_argument('--TRAIN_BATCH_SIZE', type=int, default=2)\n",
    "parser.add_argument('--ROI_RADIUS', type=float, default=4.)\n",
    "parser.add_argument('--FEATURE_SCALE', type=float, default=1/4.)\n",
    "parser.add_argument('--GAUSSIAN_SIGMA', type=float, default=4)\n",
    "parser.add_argument('--CONF_BLOCK_SIZE', type=int, default=16)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#_shift pretrain\n",
    "parser.add_argument('--WIN_OFFSET_RANGE', type=int, nargs='+', default=[100,350])\n",
    "parser.add_argument('--IMG_OFFSET_RANGE', type=int, nargs='+', default=[-100,100])\n",
    "\n",
    "\n",
    "parser.add_argument('--DEN_FACTOR', type=float, default=200.)\n",
    "parser.add_argument('--MEAN_STD', type=tuple, default=([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]))\n",
    "\n",
    "# cfg = parser.parse_args()\n",
    "cfg = parser.parse_known_args()[0]\n",
    "\n",
    "\n",
    "# data_mode = cfg.DATASET\n",
    "# datasetting = import_module(f'datasets.setting.{data_mode}')\n",
    "# cfg_data = datasetting.cfg_data\n",
    "cfg_data = cfg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameter: 19.82M\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from model.SMDCA import  SMDCANet\n",
    "\n",
    "model = SMDCANet(cfg, cfg_data)\n",
    "total = sum([param.nelement() for param in model.parameters()])\n",
    "print(\"Number of parameter: %.2fM\" % (total/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameter: 28.30M\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "\n",
    "from FMDC.model.video_crowd_count import  video_crowd_count\n",
    "sys.path.append('./')\n",
    "\n",
    "\n",
    "model = video_crowd_count(cfg, cfg_data)\n",
    "total = sum([param.nelement() for param in model.parameters()])\n",
    "print(\"Number of parameter: %.2fM\" % (total/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "video_crowd_count.forward() missing 2 required positional arguments: 'img_rgb' and 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthop\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m profile \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m768\u001b[39m, \u001b[38;5;241m1024\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m flops, params \u001b[38;5;241m=\u001b[39m \u001b[43mprofile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(flops)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(params)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/thop/profile.py:212\u001b[0m, in \u001b[0;36mprofile\u001b[0;34m(model, inputs, custom_ops, verbose, ret_layer_info, report_missing)\u001b[0m\n\u001b[1;32m    209\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(add_hooks)\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 212\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdfs_count\u001b[39m(module: nn\u001b[38;5;241m.\u001b[39mModule, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    215\u001b[0m     total_ops, total_params \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mtotal_ops\u001b[38;5;241m.\u001b[39mitem(), \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1505\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1514\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1512\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1513\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: video_crowd_count.forward() missing 2 required positional arguments: 'img_rgb' and 'target'"
     ]
    }
   ],
   "source": [
    "import thop\n",
    "from thop import profile \n",
    "input = torch.randn(4, 3, 768, 1024)\n",
    "flops, params = profile(model, inputs=(input,))\n",
    "print(flops)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
