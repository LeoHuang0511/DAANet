{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/01-30_15-29__HT21_5e-05/ep_1_iter_1000_mae_72.151_mse_72.297_seq_MAE_397.645_seq_MSE_397.645_WRAE_611.762_MIAE_46.142_MOAE_46.941.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/01-30_15-29__HT21_5e-05/ep_1_iter_2000_mae_21.141_mse_21.577_seq_MAE_161.226_seq_MSE_161.226_WRAE_248.040_MIAE_19.808_MOAE_20.391.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/01-30_15-29__HT21_5e-05/ep_2_iter_3000_mae_11.556_mse_12.384_seq_MAE_112.832_seq_MSE_112.832_WRAE_173.588_MIAE_13.798_MOAE_14.897.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/01-30_15-29__HT21_5e-05/ep_2_iter_4000_mae_3.505_mse_4.206_seq_MAE_66.905_seq_MSE_66.905_WRAE_102.930_MIAE_8.596_MOAE_10.102.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/01-30_15-29__HT21_5e-05/ep_2_iter_5000_mae_4.321_mse_4.657_seq_MAE_63.642_seq_MSE_63.642_WRAE_97.911_MIAE_8.039_MOAE_8.967.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/01-30_15-29__HT21_5e-05/ep_3_iter_6000_mae_8.002_mse_8.761_seq_MAE_56.477_seq_MSE_56.477_WRAE_86.888_MIAE_6.697_MOAE_8.401.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/01-30_15-29__HT21_5e-05/ep_3_iter_7000_mae_2.967_mse_3.671_seq_MAE_41.865_seq_MSE_41.865_WRAE_64.407_MIAE_5.164_MOAE_6.927.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/01-30_15-29__HT21_5e-05/ep_4_iter_8000_mae_2.839_mse_3.301_seq_MAE_34.799_seq_MSE_34.799_WRAE_53.537_MIAE_4.474_MOAE_6.003.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/01-30_15-29__HT21_5e-05/ep_4_iter_9000_mae_2.949_mse_3.360_seq_MAE_25.168_seq_MSE_25.168_WRAE_38.720_MIAE_3.158_MOAE_4.602.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/01-30_15-29__HT21_5e-05/ep_5_iter_11000_mae_4.182_mse_5.627_seq_MAE_12.642_seq_MSE_12.642_WRAE_19.450_MIAE_1.963_MOAE_3.161.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/01-30_15-29__HT21_5e-05/ep_5_iter_13000_mae_2.724_mse_3.428_seq_MAE_37.462_seq_MSE_37.462_WRAE_57.634_MIAE_5.066_MOAE_5.877.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/01-30_15-29__HT21_5e-05/ep_6_iter_14000_mae_2.552_mse_3.470_seq_MAE_26.790_seq_MSE_26.790_WRAE_41.215_MIAE_3.693_MOAE_5.336.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/01-30_15-29__HT21_5e-05/ep_7_iter_18000_mae_4.080_mse_5.470_seq_MAE_12.136_seq_MSE_12.136_WRAE_18.670_MIAE_2.347_MOAE_3.459.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/01-30_15-29__HT21_5e-05/ep_8_iter_20000_mae_2.451_mse_3.528_seq_MAE_25.115_seq_MSE_25.115_WRAE_38.638_MIAE_3.540_MOAE_5.596.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/01-30_15-29__HT21_5e-05/ep_8_iter_21000_mae_2.765_mse_3.198_seq_MAE_29.211_seq_MSE_29.211_WRAE_44.940_MIAE_3.780_MOAE_5.282.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/01-30_15-29__HT21_5e-05/ep_9_iter_22000_mae_8.097_mse_8.838_seq_MAE_7.078_seq_MSE_7.078_WRAE_10.890_MIAE_2.114_MOAE_3.590.pth --GPU_ID 0\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "dataset = \"HT21\"\n",
    "exp = \"01-31_14-26_NoKPI_HT21_5e-05\"\n",
    "device = \"TWCC\"\n",
    "gpu = 0\n",
    "\n",
    "if device == \"TWCC\":\n",
    "    root = \"/home/leohuang0511\"\n",
    "else:\n",
    "    root = \"/nfs/home/leo0511/Research\"\n",
    "files = sorted(glob.glob(f\"{root}/SSSP/exp/{dataset}/FT/{exp}/ep*\"))\n",
    "for file in files:\n",
    "    print(f\"python test_{dataset}.py --MODEL_PATH {file} --GPU_ID {gpu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "from importlib import import_module\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--EXP_NAME', type=str, default='')\n",
    "\n",
    "parser.add_argument('--RESUME_PATH',type=str, default='')\n",
    "parser.add_argument('--PRETRAIN_PATH',type=str, default='')\n",
    "parser.add_argument('--FROZEN', default=False, action='store_true', help=\"frozen pretrained frontend weights\")\n",
    "\n",
    "\n",
    "parser.add_argument('--GPU_ID', type=str, default='0')\n",
    "parser.add_argument('--SEED', type=int, default=3035)\n",
    "parser.add_argument('--DATASET', type=str, default='HT21')\n",
    "parser.add_argument('--TASK', type=str, default='FT')\n",
    "parser.add_argument('--PRINT_FREQ', type=int, default=20)\n",
    "parser.add_argument('--SAVE_VIS_FREQ', type=int, default=500)\n",
    "parser.add_argument('--BACKBONE', type=str, default='vgg')\n",
    "\n",
    "\n",
    "parser.add_argument('--LR_MIN', type=float, default=1e-6)\n",
    "parser.add_argument('--LR_BASE', type=float, default=5e-5, help='density branch')\n",
    "parser.add_argument('--LR_THRE', type=float, default=1e-4, help='mask branch')\n",
    "parser.add_argument('--LR_DECAY', type=float, default=0.95)\n",
    "parser.add_argument('--WEIGHT_DECAY', type=float, default=1e-5)\n",
    "parser.add_argument('--WARMUP_EPOCH', type=int, default=3, help='number of epochs for warm up step in cosine annealing lr scheduler')\n",
    "parser.add_argument('--MAX_EPOCH', type=int, default=20)\n",
    "parser.add_argument('--WORKER', type=int, default=4)\n",
    "\n",
    "\n",
    "parser.add_argument('--CON_WEIGHT', type=float, default=0.5)\n",
    "parser.add_argument('--SCALE_WEIGHT', type=float, nargs='+', default=[2,0.1,0.01])\n",
    "parser.add_argument('--CNT_WEIGHT', type=float, default=10)\n",
    "parser.add_argument('--MASK_WEIGHT', type=float, default=1)\n",
    "parser.add_argument('--IO_WEIGHT', type=float, default=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#_test or val\n",
    "parser.add_argument('--VAL_FREQ', type=int, default=1000)\n",
    "parser.add_argument('--VAL_START', type=int, default=1)\n",
    "parser.add_argument('--VAL_BATCH_SIZE', type=int, default=1)\n",
    "\n",
    "\n",
    "\n",
    "#_train\n",
    "parser.add_argument('--TRAIN_SIZE', type=int, nargs='+', default=[768,1024])\n",
    "parser.add_argument('--TRAIN_FRAME_INTERVALS', type=int, nargs='+', default=[40, 85])\n",
    "parser.add_argument('--TRAIN_BATCH_SIZE', type=int, default=2)\n",
    "parser.add_argument('--ROI_RADIUS', type=float, default=4.)\n",
    "parser.add_argument('--FEATURE_SCALE', type=float, default=1/4.)\n",
    "parser.add_argument('--GAUSSIAN_SIGMA', type=float, default=4)\n",
    "parser.add_argument('--CONF_BLOCK_SIZE', type=int, default=16)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#_shift pretrain\n",
    "parser.add_argument('--WIN_OFFSET_RANGE', type=int, nargs='+', default=[100,350])\n",
    "parser.add_argument('--IMG_OFFSET_RANGE', type=int, nargs='+', default=[-100,100])\n",
    "\n",
    "\n",
    "parser.add_argument('--DEN_FACTOR', type=float, default=200.)\n",
    "parser.add_argument('--MEAN_STD', type=tuple, default=([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]))\n",
    "\n",
    "# cfg = parser.parse_args()\n",
    "cfg = parser.parse_known_args()[0]\n",
    "\n",
    "\n",
    "# data_mode = cfg.DATASET\n",
    "# datasetting = import_module(f'datasets.setting.{data_mode}')\n",
    "# cfg_data = datasetting.cfg_data\n",
    "cfg_data = cfg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameter: 19.82M\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from model.SMDCA import  SMDCANet\n",
    "\n",
    "model = SMDCANet(cfg, cfg_data)\n",
    "total = sum([param.nelement() for param in model.parameters()])\n",
    "print(\"Number of parameter: %.2fM\" % (total/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameter: 28.30M\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "\n",
    "from FMDC.model.video_crowd_count import  video_crowd_count\n",
    "sys.path.append('./')\n",
    "\n",
    "\n",
    "model = video_crowd_count(cfg, cfg_data)\n",
    "total = sum([param.nelement() for param in model.parameters()])\n",
    "print(\"Number of parameter: %.2fM\" % (total/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "video_crowd_count.forward() missing 2 required positional arguments: 'img_rgb' and 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthop\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m profile \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m768\u001b[39m, \u001b[38;5;241m1024\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m flops, params \u001b[38;5;241m=\u001b[39m \u001b[43mprofile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(flops)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(params)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/thop/profile.py:212\u001b[0m, in \u001b[0;36mprofile\u001b[0;34m(model, inputs, custom_ops, verbose, ret_layer_info, report_missing)\u001b[0m\n\u001b[1;32m    209\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(add_hooks)\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 212\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdfs_count\u001b[39m(module: nn\u001b[38;5;241m.\u001b[39mModule, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    215\u001b[0m     total_ops, total_params \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mtotal_ops\u001b[38;5;241m.\u001b[39mitem(), \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1505\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1514\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1512\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1513\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: video_crowd_count.forward() missing 2 required positional arguments: 'img_rgb' and 'target'"
     ]
    }
   ],
   "source": [
    "import thop\n",
    "from thop import profile \n",
    "input = torch.randn(4, 3, 768, 1024)\n",
    "flops, params = profile(model, inputs=(input,))\n",
    "print(flops)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
