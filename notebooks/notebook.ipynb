{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python test_CARLA.py --MODEL_PATH /nfs/home/leo0511/Research/SSSP/exp/CARLA/FT/02-05_07-15_vgg_con01_CARLA_5e-05_0.0001/ep_11_iter_18000_mae_15.839_mse_16.581_seq_MAE_22.667_seq_MSE_22.667_WRAE_10.119_MIAE_2.985_MOAE_1.910.pth --GPU_ID 2 --TEST_INTERVALS 55\n",
      "python test_CARLA.py --MODEL_PATH /nfs/home/leo0511/Research/SSSP/exp/CARLA/FT/02-05_07-15_vgg_con01_CARLA_5e-05_0.0001/ep_17_iter_28000_mae_18.407_mse_19.211_seq_MAE_8.886_seq_MSE_8.886_WRAE_3.967_MIAE_2.026_MOAE_2.120.pth --GPU_ID 2 --TEST_INTERVALS 55\n",
      "python test_CARLA.py --MODEL_PATH /nfs/home/leo0511/Research/SSSP/exp/CARLA/FT/02-05_07-15_vgg_con01_CARLA_5e-05_0.0001/ep_18_iter_29000_mae_22.347_mse_23.269_seq_MAE_10.277_seq_MSE_10.277_WRAE_4.588_MIAE_2.303_MOAE_1.846.pth --GPU_ID 2 --TEST_INTERVALS 55\n",
      "python test_CARLA.py --MODEL_PATH /nfs/home/leo0511/Research/SSSP/exp/CARLA/FT/02-05_07-15_vgg_con01_CARLA_5e-05_0.0001/ep_1_iter_1000_mae_3.100_mse_4.042_seq_MAE_559.109_seq_MSE_559.109_WRAE_249.602_MIAE_29.721_MOAE_29.124.pth --GPU_ID 2 --TEST_INTERVALS 55\n",
      "python test_CARLA.py --MODEL_PATH /nfs/home/leo0511/Research/SSSP/exp/CARLA/FT/02-05_07-15_vgg_con01_CARLA_5e-05_0.0001/ep_2_iter_2000_mae_27.353_mse_28.226_seq_MAE_413.921_seq_MSE_413.921_WRAE_184.786_MIAE_23.561_MOAE_23.194.pth --GPU_ID 2 --TEST_INTERVALS 55\n",
      "python test_CARLA.py --MODEL_PATH /nfs/home/leo0511/Research/SSSP/exp/CARLA/FT/02-05_07-15_vgg_con01_CARLA_5e-05_0.0001/ep_3_iter_5000_mae_13.207_mse_14.013_seq_MAE_330.875_seq_MSE_330.875_WRAE_147.712_MIAE_18.299_MOAE_16.191.pth --GPU_ID 2 --TEST_INTERVALS 55\n",
      "python test_CARLA.py --MODEL_PATH /nfs/home/leo0511/Research/SSSP/exp/CARLA/FT/02-05_07-15_vgg_con01_CARLA_5e-05_0.0001/ep_5_iter_7000_mae_7.808_mse_8.413_seq_MAE_193.317_seq_MSE_193.317_WRAE_86.302_MIAE_10.704_MOAE_10.581.pth --GPU_ID 2 --TEST_INTERVALS 55\n",
      "python test_CARLA.py --MODEL_PATH /nfs/home/leo0511/Research/SSSP/exp/CARLA/FT/02-05_07-15_vgg_con01_CARLA_5e-05_0.0001/ep_5_iter_8000_mae_19.082_mse_19.989_seq_MAE_182.071_seq_MSE_182.071_WRAE_81.282_MIAE_10.816_MOAE_9.410.pth --GPU_ID 2 --TEST_INTERVALS 55\n",
      "python test_CARLA.py --MODEL_PATH /nfs/home/leo0511/Research/SSSP/exp/CARLA/FT/02-05_07-15_vgg_con01_CARLA_5e-05_0.0001/ep_7_iter_11000_mae_16.436_mse_17.047_seq_MAE_51.700_seq_MSE_51.700_WRAE_23.080_MIAE_3.828_MOAE_3.635.pth --GPU_ID 2 --TEST_INTERVALS 55\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "dataset = \"CARLA\"\n",
    "exp = \"02-05_07-15_vgg_con01_CARLA_5e-05_0.0001\"\n",
    "device = \"\"\n",
    "gpu = 2\n",
    "\n",
    "if device == \"TWCC\":\n",
    "    gpu = 0\n",
    "\n",
    "    root = \"/home/leohuang0511\"\n",
    "else:\n",
    "    root = \"/nfs/home/leo0511/Research\"\n",
    "files = sorted(glob.glob(f\"{root}/SSSP/exp/{dataset}/FT/{exp}/ep*\"))\n",
    "for file in files:\n",
    "    print(f\"python test_{dataset}.py --MODEL_PATH {file} --GPU_ID {gpu} --TEST_INTERVALS 55\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "from importlib import import_module\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--EXP_NAME', type=str, default='')\n",
    "\n",
    "parser.add_argument('--RESUME_PATH',type=str, default='')\n",
    "parser.add_argument('--PRETRAIN_PATH',type=str, default='')\n",
    "parser.add_argument('--FROZEN', default=False, action='store_true', help=\"frozen pretrained frontend weights\")\n",
    "\n",
    "\n",
    "parser.add_argument('--GPU_ID', type=str, default='0')\n",
    "parser.add_argument('--SEED', type=int, default=3035)\n",
    "parser.add_argument('--DATASET', type=str, default='HT21')\n",
    "parser.add_argument('--TASK', type=str, default='FT')\n",
    "parser.add_argument('--PRINT_FREQ', type=int, default=20)\n",
    "parser.add_argument('--SAVE_VIS_FREQ', type=int, default=500)\n",
    "parser.add_argument('--BACKBONE', type=str, default='vgg')\n",
    "\n",
    "\n",
    "parser.add_argument('--LR_MIN', type=float, default=1e-6)\n",
    "parser.add_argument('--LR_BASE', type=float, default=5e-5, help='density branch')\n",
    "parser.add_argument('--LR_THRE', type=float, default=1e-4, help='mask branch')\n",
    "parser.add_argument('--LR_DECAY', type=float, default=0.95)\n",
    "parser.add_argument('--WEIGHT_DECAY', type=float, default=1e-5)\n",
    "parser.add_argument('--WARMUP_EPOCH', type=int, default=3, help='number of epochs for warm up step in cosine annealing lr scheduler')\n",
    "parser.add_argument('--MAX_EPOCH', type=int, default=20)\n",
    "parser.add_argument('--WORKER', type=int, default=4)\n",
    "\n",
    "\n",
    "parser.add_argument('--CON_WEIGHT', type=float, default=0.5)\n",
    "parser.add_argument('--SCALE_WEIGHT', type=float, nargs='+', default=[2,0.1,0.01])\n",
    "parser.add_argument('--CNT_WEIGHT', type=float, default=10)\n",
    "parser.add_argument('--MASK_WEIGHT', type=float, default=1)\n",
    "parser.add_argument('--IO_WEIGHT', type=float, default=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#_test or val\n",
    "parser.add_argument('--VAL_FREQ', type=int, default=1000)\n",
    "parser.add_argument('--VAL_START', type=int, default=1)\n",
    "parser.add_argument('--VAL_BATCH_SIZE', type=int, default=1)\n",
    "\n",
    "\n",
    "\n",
    "#_train\n",
    "parser.add_argument('--TRAIN_SIZE', type=int, nargs='+', default=[768,1024])\n",
    "parser.add_argument('--TRAIN_FRAME_INTERVALS', type=int, nargs='+', default=[40, 85])\n",
    "parser.add_argument('--TRAIN_BATCH_SIZE', type=int, default=2)\n",
    "parser.add_argument('--ROI_RADIUS', type=float, default=4.)\n",
    "parser.add_argument('--FEATURE_SCALE', type=float, default=1/4.)\n",
    "parser.add_argument('--GAUSSIAN_SIGMA', type=float, default=4)\n",
    "parser.add_argument('--CONF_BLOCK_SIZE', type=int, default=16)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#_shift pretrain\n",
    "parser.add_argument('--WIN_OFFSET_RANGE', type=int, nargs='+', default=[100,350])\n",
    "parser.add_argument('--IMG_OFFSET_RANGE', type=int, nargs='+', default=[-100,100])\n",
    "\n",
    "\n",
    "parser.add_argument('--DEN_FACTOR', type=float, default=200.)\n",
    "parser.add_argument('--MEAN_STD', type=tuple, default=([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]))\n",
    "\n",
    "# cfg = parser.parse_args()\n",
    "cfg = parser.parse_known_args()[0]\n",
    "\n",
    "\n",
    "# data_mode = cfg.DATASET\n",
    "# datasetting = import_module(f'datasets.setting.{data_mode}')\n",
    "# cfg_data = datasetting.cfg_data\n",
    "cfg_data = cfg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameter: 19.82M\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from model.SMDCA import  SMDCANet\n",
    "\n",
    "model = SMDCANet(cfg, cfg_data)\n",
    "total = sum([param.nelement() for param in model.parameters()])\n",
    "print(\"Number of parameter: %.2fM\" % (total/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameter: 28.30M\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "\n",
    "from FMDC.model.video_crowd_count import  video_crowd_count\n",
    "sys.path.append('./')\n",
    "\n",
    "\n",
    "model = video_crowd_count(cfg, cfg_data)\n",
    "total = sum([param.nelement() for param in model.parameters()])\n",
    "print(\"Number of parameter: %.2fM\" % (total/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "video_crowd_count.forward() missing 2 required positional arguments: 'img_rgb' and 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthop\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m profile \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m768\u001b[39m, \u001b[38;5;241m1024\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m flops, params \u001b[38;5;241m=\u001b[39m \u001b[43mprofile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(flops)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(params)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/thop/profile.py:212\u001b[0m, in \u001b[0;36mprofile\u001b[0;34m(model, inputs, custom_ops, verbose, ret_layer_info, report_missing)\u001b[0m\n\u001b[1;32m    209\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(add_hooks)\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 212\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdfs_count\u001b[39m(module: nn\u001b[38;5;241m.\u001b[39mModule, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    215\u001b[0m     total_ops, total_params \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mtotal_ops\u001b[38;5;241m.\u001b[39mitem(), \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1505\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1514\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1512\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1513\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: video_crowd_count.forward() missing 2 required positional arguments: 'img_rgb' and 'target'"
     ]
    }
   ],
   "source": [
    "import thop\n",
    "from thop import profile \n",
    "input = torch.randn(4, 3, 768, 1024)\n",
    "flops, params = profile(model, inputs=(input,))\n",
    "print(flops)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
