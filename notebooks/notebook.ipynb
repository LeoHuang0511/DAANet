{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/01-31_14-26_NoKPI_HT21_5e-05/ep_12_iter_30000_mae_8.822_mse_9.357_seq_MAE_13.376_seq_MSE_13.376_WRAE_20.578_MIAE_3.136_MOAE_5.321.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/01-31_14-26_NoKPI_HT21_5e-05/ep_1_iter_1000_mae_18.574_mse_19.004_seq_MAE_176.059_seq_MSE_176.059_WRAE_270.860_MIAE_22.292_MOAE_22.972.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/01-31_14-26_NoKPI_HT21_5e-05/ep_1_iter_2000_mae_8.698_mse_9.488_seq_MAE_120.261_seq_MSE_120.261_WRAE_185.017_MIAE_15.795_MOAE_16.853.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/01-31_14-26_NoKPI_HT21_5e-05/ep_2_iter_3000_mae_3.577_mse_4.410_seq_MAE_70.762_seq_MSE_70.762_WRAE_108.864_MIAE_10.196_MOAE_11.110.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/01-31_14-26_NoKPI_HT21_5e-05/ep_2_iter_5000_mae_6.990_mse_8.103_seq_MAE_77.278_seq_MSE_77.278_WRAE_118.890_MIAE_9.626_MOAE_11.635.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/01-31_14-26_NoKPI_HT21_5e-05/ep_3_iter_6000_mae_5.528_mse_6.149_seq_MAE_73.758_seq_MSE_73.758_WRAE_113.473_MIAE_9.530_MOAE_10.916.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/01-31_14-26_NoKPI_HT21_5e-05/ep_3_iter_7000_mae_6.316_mse_6.535_seq_MAE_65.499_seq_MSE_65.499_WRAE_100.768_MIAE_8.195_MOAE_9.817.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/01-31_14-26_NoKPI_HT21_5e-05/ep_4_iter_8000_mae_2.124_mse_2.727_seq_MAE_55.267_seq_MSE_55.267_WRAE_85.026_MIAE_7.802_MOAE_9.447.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/01-31_14-26_NoKPI_HT21_5e-05/ep_4_iter_9000_mae_2.737_mse_3.117_seq_MAE_40.197_seq_MSE_40.197_WRAE_61.841_MIAE_5.007_MOAE_6.759.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/01-31_14-26_NoKPI_HT21_5e-05/ep_5_iter_12000_mae_4.916_mse_5.741_seq_MAE_28.039_seq_MSE_28.039_WRAE_43.138_MIAE_4.153_MOAE_5.996.pth --GPU_ID 0\n",
      "python test_HT21.py --MODEL_PATH /home/leohuang0511/SSSP/exp/HT21/FT/01-31_14-26_NoKPI_HT21_5e-05/ep_6_iter_14000_mae_5.754_mse_6.674_seq_MAE_25.863_seq_MSE_25.863_WRAE_39.789_MIAE_3.800_MOAE_5.681.pth --GPU_ID 0\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "dataset = \"HT21\"\n",
    "exp = \"01-31_14-26_NoKPI_HT21_5e-05\"\n",
    "device = \"TWCC\"\n",
    "gpu = 0\n",
    "\n",
    "if device == \"TWCC\":\n",
    "    root = \"/home/leohuang0511\"\n",
    "else:\n",
    "    root = \"/nfs/home/leo0511/Research\"\n",
    "files = sorted(glob.glob(f\"{root}/SSSP/exp/{dataset}/FT/{exp}/ep*\"))\n",
    "for file in files:\n",
    "    print(f\"python test_{dataset}.py --MODEL_PATH {file} --GPU_ID {gpu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "from importlib import import_module\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--EXP_NAME', type=str, default='')\n",
    "\n",
    "parser.add_argument('--RESUME_PATH',type=str, default='')\n",
    "parser.add_argument('--PRETRAIN_PATH',type=str, default='')\n",
    "parser.add_argument('--FROZEN', default=False, action='store_true', help=\"frozen pretrained frontend weights\")\n",
    "\n",
    "\n",
    "parser.add_argument('--GPU_ID', type=str, default='0')\n",
    "parser.add_argument('--SEED', type=int, default=3035)\n",
    "parser.add_argument('--DATASET', type=str, default='HT21')\n",
    "parser.add_argument('--TASK', type=str, default='FT')\n",
    "parser.add_argument('--PRINT_FREQ', type=int, default=20)\n",
    "parser.add_argument('--SAVE_VIS_FREQ', type=int, default=500)\n",
    "parser.add_argument('--BACKBONE', type=str, default='vgg')\n",
    "\n",
    "\n",
    "parser.add_argument('--LR_MIN', type=float, default=1e-6)\n",
    "parser.add_argument('--LR_BASE', type=float, default=5e-5, help='density branch')\n",
    "parser.add_argument('--LR_THRE', type=float, default=1e-4, help='mask branch')\n",
    "parser.add_argument('--LR_DECAY', type=float, default=0.95)\n",
    "parser.add_argument('--WEIGHT_DECAY', type=float, default=1e-5)\n",
    "parser.add_argument('--WARMUP_EPOCH', type=int, default=3, help='number of epochs for warm up step in cosine annealing lr scheduler')\n",
    "parser.add_argument('--MAX_EPOCH', type=int, default=20)\n",
    "parser.add_argument('--WORKER', type=int, default=4)\n",
    "\n",
    "\n",
    "parser.add_argument('--CON_WEIGHT', type=float, default=0.5)\n",
    "parser.add_argument('--SCALE_WEIGHT', type=float, nargs='+', default=[2,0.1,0.01])\n",
    "parser.add_argument('--CNT_WEIGHT', type=float, default=10)\n",
    "parser.add_argument('--MASK_WEIGHT', type=float, default=1)\n",
    "parser.add_argument('--IO_WEIGHT', type=float, default=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#_test or val\n",
    "parser.add_argument('--VAL_FREQ', type=int, default=1000)\n",
    "parser.add_argument('--VAL_START', type=int, default=1)\n",
    "parser.add_argument('--VAL_BATCH_SIZE', type=int, default=1)\n",
    "\n",
    "\n",
    "\n",
    "#_train\n",
    "parser.add_argument('--TRAIN_SIZE', type=int, nargs='+', default=[768,1024])\n",
    "parser.add_argument('--TRAIN_FRAME_INTERVALS', type=int, nargs='+', default=[40, 85])\n",
    "parser.add_argument('--TRAIN_BATCH_SIZE', type=int, default=2)\n",
    "parser.add_argument('--ROI_RADIUS', type=float, default=4.)\n",
    "parser.add_argument('--FEATURE_SCALE', type=float, default=1/4.)\n",
    "parser.add_argument('--GAUSSIAN_SIGMA', type=float, default=4)\n",
    "parser.add_argument('--CONF_BLOCK_SIZE', type=int, default=16)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#_shift pretrain\n",
    "parser.add_argument('--WIN_OFFSET_RANGE', type=int, nargs='+', default=[100,350])\n",
    "parser.add_argument('--IMG_OFFSET_RANGE', type=int, nargs='+', default=[-100,100])\n",
    "\n",
    "\n",
    "parser.add_argument('--DEN_FACTOR', type=float, default=200.)\n",
    "parser.add_argument('--MEAN_STD', type=tuple, default=([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]))\n",
    "\n",
    "# cfg = parser.parse_args()\n",
    "cfg = parser.parse_known_args()[0]\n",
    "\n",
    "\n",
    "# data_mode = cfg.DATASET\n",
    "# datasetting = import_module(f'datasets.setting.{data_mode}')\n",
    "# cfg_data = datasetting.cfg_data\n",
    "cfg_data = cfg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameter: 19.82M\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from model.SMDCA import  SMDCANet\n",
    "\n",
    "model = SMDCANet(cfg, cfg_data)\n",
    "total = sum([param.nelement() for param in model.parameters()])\n",
    "print(\"Number of parameter: %.2fM\" % (total/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameter: 28.30M\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "\n",
    "from FMDC.model.video_crowd_count import  video_crowd_count\n",
    "sys.path.append('./')\n",
    "\n",
    "\n",
    "model = video_crowd_count(cfg, cfg_data)\n",
    "total = sum([param.nelement() for param in model.parameters()])\n",
    "print(\"Number of parameter: %.2fM\" % (total/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "video_crowd_count.forward() missing 2 required positional arguments: 'img_rgb' and 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthop\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m profile \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m768\u001b[39m, \u001b[38;5;241m1024\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m flops, params \u001b[38;5;241m=\u001b[39m \u001b[43mprofile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(flops)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(params)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/thop/profile.py:212\u001b[0m, in \u001b[0;36mprofile\u001b[0;34m(model, inputs, custom_ops, verbose, ret_layer_info, report_missing)\u001b[0m\n\u001b[1;32m    209\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(add_hooks)\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 212\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdfs_count\u001b[39m(module: nn\u001b[38;5;241m.\u001b[39mModule, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    215\u001b[0m     total_ops, total_params \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mtotal_ops\u001b[38;5;241m.\u001b[39mitem(), \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1505\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1514\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1512\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1513\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: video_crowd_count.forward() missing 2 required positional arguments: 'img_rgb' and 'target'"
     ]
    }
   ],
   "source": [
    "import thop\n",
    "from thop import profile \n",
    "input = torch.randn(4, 3, 768, 1024)\n",
    "flops, params = profile(model, inputs=(input,))\n",
    "print(flops)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
